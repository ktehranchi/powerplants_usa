{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabriels Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADS_PATH = os.path.join('../resources/WECC_ADS/downloads/2032/Public Data')\n",
    "ads= pd.read_csv(ADS_PATH + '/GeneratorList.csv',skiprows=2, encoding='unicode_escape')\n",
    "ads = ads[ads['State'].isin(['NM', 'AZ', 'CA', 'WA', 'OR', 'ID', 'WY', 'MT', 'UT', 'SD', 'CO', 'NV', 'NE', '0', 'TX'])]\n",
    "ads['Long Name'] = ads['Long Name'].astype(str)\n",
    "ads['Commission Date'] = pd.to_datetime(ads['Commission Date'], format='#%Y-%m-%d#')\n",
    "ads['Retirement Date'] = pd.to_datetime(ads['Retirement Date'], format='#%Y-%m-%d#')\n",
    "ads['Name'] = ads['Name'].str.replace(\" \", \"\")\n",
    "ads['Name'] = ads['Name'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "ads['Long Name'] = ads['Long Name'].str.replace(\" \", \"\")\n",
    "ads['Long Name'] = ads['Long Name'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "ads['SubType'] = ads['SubType'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "ads.rename({'Name': 'ads_name', 'Long Name': 'ads_long_name', 'SubType': 'subtype','Commission Date':'commission_date','Retirement Date':'retirement_date','Area Name':'balancing_area'}, axis=1, inplace=True)\n",
    "ads.rename(str.lower, axis='columns', inplace=True)\n",
    "ads['long id'] = ads['long id'].astype(str)\n",
    "ads.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_long_id(row):\n",
    "    if row['long id'].split('-')[0] == row['state']:\n",
    "         id_list = row['long id'].split('-')[1:]\n",
    "    else:\n",
    "        id_list = row['long id']\n",
    "    if len(id_list) > 2:\n",
    "        vals=  pd.Series([id_list[0], id_list[1] + '-' + id_list[2]])\n",
    "    elif len(id_list) == 2:\n",
    "        vals= pd.Series([id_list[0], id_list[1]])\n",
    "    elif len(id_list) == 1:\n",
    "        vals= pd.Series([id_list[0], None])\n",
    "    elif len(id_list) == 0:\n",
    "        vals= pd.Series([None, None])\n",
    "    vals.astype(str)\n",
    "    return vals\n",
    "\n",
    "# Apply the function to the 'long id' column\n",
    "ads[['plant_id_ads','generator_id_ads']] = ads.apply(split_long_id, axis=1)\n",
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ads['eia_id_ads'] = ads['long id'].str.split('-').str[1].fillna(99999)\n",
    "# ads['generator_id_ads'] = ads['long id'].str.split('-').str[2].fillna(99999).astype(str)\n",
    "# ads['eia_id_ads'] = ads['eia_id_ads'].replace('N/A', '9999').replace('??', '9999').replace(['',], '9999')\n",
    "# ads.loc[~ads['eia_id_ads'].astype(str).str.isdigit(),['eia_id_ads']] = 99999  #replace all non integer values with 9999\n",
    "# #TODO: THERE IS a wind plant (id: 57621) with three eia_ids that need to be split up since they exist.\n",
    "# # ads.iloc[4864] #issue with this row\n",
    "# # ads[~ads['eia_id_ads'].astype(str).str.isdigit()][['servicestatus', 'commission_date', 'retirement_date', 'devstatus','maxcap(mw)','eia_id_ads']].sort_values(by='maxcap(mw)', ascending=False).head(30)\n",
    "# # ads.loc[ads[~ads['eia_id_ads'].astype(str).str.isdigit()]['maxcap(mw)'].sort_values(ascending=False).head(20).index]\n",
    "# ads['eia_id_ads'] = ads['eia_id_ads'].astype(int).astype(str)\n",
    "# # ads['gen_id_ads'] = ads['long id'].str.split('-').str[2].astype(str)\n",
    "# ads.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2032 Network Preparation\n",
    "### Populate ADS data with lat lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_ads_mapping = pd.read_csv('../repo_data/eia_mappings/eia_ads_generator_mapping.csv')\n",
    "lat_dict = dict(zip(eia_ads_mapping['GeneratorKey'], eia_ads_mapping['latitude']))\n",
    "lon_dict = dict(zip(eia_ads_mapping['GeneratorKey'], eia_ads_mapping['longitude']))\n",
    "eia_id_dict = dict(zip(eia_ads_mapping['GeneratorKey'], eia_ads_mapping['plant_id_eia']))\n",
    "# combine lat_dict and lon_dict into one dictionary\n",
    "lat_lon_dict = {k: (lat_dict[k], lon_dict[k]) for k in lat_dict}\n",
    "ads['lat'] = ads['generatorkey'].map(lat_lon_dict).str[0]\n",
    "ads['lon'] = ads['generatorkey'].map(lat_lon_dict).str[1]\n",
    "ads['plant_id_eia'] = ads['generatorkey'].map(eia_id_dict)\n",
    "print('Total Num ADS Gens: ', ads.shape[0])\n",
    "print('Number of ads with missing lat long: ', ads['lat'].isna().sum())\n",
    "ads_matched = ads[~(ads['lat'].isnull() | ads['lon'].isnull())]\n",
    "ads_matched\n",
    "# bus_locs = ads.groupby('bus id').agg({'lat': 'mean', 'lon': 'mean'}).reset_index().dropna()\n",
    "# ads[['lat', 'lon']] = ads[['lat', 'lon']].fillna(ads['bus id'].map(bus_locs.set_index('bus id')['lat']))\n",
    "# ads[['lat', 'lon']] = ads[['lat', 'lon']].fillna(ads['bus id'].map(bus_locs.set_index('bus id')['lon']))\n",
    "# print('Number of ads with missing lat long: ', ads['lat'].isna().sum())\n",
    "# #didnt do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying other methods to match non-direct matches\n",
    "ads_unmatched = ads[(ads['lat'].isnull() | ads['lon'].isnull())]\n",
    "print(ads_unmatched.columns)\n",
    "ads_unmatched = ads_unmatched[ads_unmatched.btm == '#FALSE#'] #TODO: filtering out BTM resources for now\n",
    "eia_loc.plant_id_eia = eia_loc.plant_id_eia.astype(str)\n",
    "matched_2 = pd.merge(ads_unmatched,eia_loc,left_on= 'plant_id_ads', right_on='plant_id_eia', how = 'inner')\n",
    "matched_2 = matched_2.drop(columns=['lat','lon']).rename(columns={'Latitude':'lat','Longitude':'lon'})\n",
    "ads_matched_2 = pd.concat([ads_matched, matched_2])\n",
    "ads_unmatched = ads_unmatched[~ads_unmatched.generatorkey.isin(matched_2.generatorkey)]\n",
    "# ads_unmatched.to_csv('ads_unmatched.csv')\n",
    "ads_eia_mapping = ads_matched_2[['generatorkey','ads_name','long id', 'bus id', 'bus name', 'devstatus', 'balancing_area', 'region name', 'plant_id_ads','plant_id_eia', 'generator_id_ads', 'lat', 'lon']]\n",
    "ads_eia_mapping.to_csv('/Users/kamrantehranchi/Local_Documents/pypsa-usa/workflow/repo_data/eia_mappings/eia_ads_generator_mapping_updated.csv',index=True)\n",
    "ads_eia_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Network Preparation\n",
    "### Populate EIA data with thermal ramp rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return datatype of each column in a eia_plant_locs\n",
    "print(eia_plants_locs.dtypes)\n",
    "eia_plants_locs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eia_plants_locs.groupby('plant_id_eia').agg({'capacity_mw': 'mean', 'summer_capacity_mw': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_plants_locs_thermal = eia_plants_locs[~eia_plants_locs.tech_type.isin(['Solar','Hydro','Wind','Storage',])]\n",
    "eia_plants_locs_thermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(eia_plants_locs_thermal, ads_eia_mapping, how='inner', left_on=['Plant Code','generator_id'], right_on=['plant_id_eia','generator_id_ads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_eia_mapping.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_thermal= pd.read_csv(ADS_PATH + '/Thermal_General_Info.csv',skiprows=1, )#encoding='unicode_escape')\n",
    "ads_thermal.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_thermal = pd.merge(eia_plants_locs, ads_eia_mapping[['plant_id_ads','generator_id_ads']], left_on=['plant_id_eia','generator_id'], right_on=['plant_id_ads','generator_id_ads'], how='left')\n",
    "print(merged_thermal.columns)\n",
    "merged_thermal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pudl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
